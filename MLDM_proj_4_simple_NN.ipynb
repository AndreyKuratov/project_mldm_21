{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MLDM-proj-4 simple NN",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNSOXHuQV7oNIKeXSo7idbb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AndreyKuratov/project_mldm_21/blob/main/MLDM_proj_4_simple_NN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n1O0b6sJxt2N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82722e9d-687b-40d8-fd24-993469d118da"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Загрузка библиотек"
      ],
      "metadata": {
        "id": "UK7JUlHn0vgE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import soundfile as sf\n",
        "import scipy.signal as signal\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "\n",
        "import os\n",
        "import csv\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "\n",
        "import librosa as lb \n",
        "import librosa.display\n",
        "import matplotlib.pyplot as plt\n",
        "import IPython.display as ipd\n",
        "\n",
        "from skimage.transform import resize\n",
        "from scipy import stats\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from skimage.transform import resize"
      ],
      "metadata": {
        "id": "DEA_xJoYy967"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Загрузка данных и меток"
      ],
      "metadata": {
        "id": "2qKrIHfd0z8D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "PATH_TO_DIR = '/content/drive/MyDrive/mldm21_project/'\n",
        "PATH_TO_SAVE = '/content/drive/MyDrive/mldm21_project/'\n",
        "\n",
        "data = np.load(PATH_TO_SAVE+'sr_48e3_nfft_2e11_hlop_2e9_pict_256x512_u8.npz',allow_pickle=True)\n",
        "# 'imgs' 'labels'\n",
        "labels = np.load(PATH_TO_SAVE+'labels_simple.npz')\n",
        "# 'files_fp' 'labels_fp' 'files_tp' 'labels_tp'\n",
        "\n",
        "labels_pd_fp = pd.read_csv('/content/drive/MyDrive/mldm21_project/train_fp.csv')\n",
        "labels_pd_tp = pd.read_csv('/content/drive/MyDrive/mldm21_project/train_tp.csv')\n"
      ],
      "metadata": {
        "id": "q3vIuJzc0yyF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "пордок метод одиаков:"
      ],
      "metadata": {
        "id": "Nc7H_WJIDtDm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.sum(data['labels']!=labels['files_tp'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mmduGXoj_ucE",
        "outputId": "324aa6d0-d555-4d2c-fd81-8328392d5528"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Выбор меток которые соотвествуют TP с одним полезным сигналом, а так же преобразование выбор матриц-рисунков для этих меток"
      ],
      "metadata": {
        "id": "wf6R5xX3DxBd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lbl,cnt_lbl = np.unique(labels_pd_tp['recording_id'].values,return_counts=True)"
      ],
      "metadata": {
        "id": "-uxxOMHyAWBW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lbl_single = lbl[cnt_lbl==1]\n",
        "length_1tp = len(lbl_single)\n",
        "print(length_1tp)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R1zloePoFDVH",
        "outputId": "92ea6d95-b95b-4653-8dff-0f646ac9edd5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1065\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Извлечение данных"
      ],
      "metadata": {
        "id": "7j_YbT9sGCWd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mask = np.isin(data['labels'], lbl_single)"
      ],
      "metadata": {
        "id": "7jiSLmGbFENI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_to_nn = data['imgs'][mask].copy()\n",
        "labels_to_nn = labels['labels_tp'][mask].copy()"
      ],
      "metadata": {
        "id": "VJ1YwFwdGbvx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.savez(PATH_TO_SAVE+'1signal_tp',data=data_to_nn,labels=labels_to_nn)"
      ],
      "metadata": {
        "id": "n1yqlyktHCsy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Исползование моделей"
      ],
      "metadata": {
        "id": "ZYKIA_sfT3cX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision.models as models\n",
        "import torch\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "\n",
        "#resnet18 = models.resnet18()\n",
        "#alexnet = models.alexnet()\n",
        "#vgg16 = models.vgg16()\n",
        "#squeezenet = models.squeezenet1_0()\n",
        "#densenet = models.densenet161()\n",
        "#inception = models.inception_v3()\n",
        "#googlenet = models.googlenet()\n",
        "#shufflenet = models.shufflenet_v2_x1_0()\n",
        "#mobilenet_v2 = models.mobilenet_v2()\n",
        "#mobilenet_v3_large = models.mobilenet_v3_large()\n",
        "#mobilenet_v3_small = models.mobilenet_v3_small()\n",
        "#resnext50_32x4d = models.resnext50_32x4d()"
      ],
      "metadata": {
        "id": "H_2KEuSoHQnr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_CLASSES = 3\n",
        "\n",
        "\n",
        "num_classes = NUM_CLASSES"
      ],
      "metadata": {
        "id": "kaJiMRzFSds4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "*   **resnet18,34,50**\n",
        "*   **vgg16**\n",
        "*   **alexnet**\n",
        "*   **squeezenet**\n",
        "*   **inception**\n",
        "*  **mobilenet_v3_small**\n",
        "\n"
      ],
      "metadata": {
        "id": "X5YqEDsyOehg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "resnet18 = models.resnet18()\n",
        "resnet18.fc = nn.Linear(512, num_classes)\n",
        "\n",
        "resnet34 = models.resnet34()\n",
        "resnet34.fc = nn.Linear(512, num_classes)\n",
        "\n",
        "resnet50 = models.resnet50()\n",
        "resnet50.fc = nn.Linear(2048, num_classes)\n",
        "\n",
        "\n",
        "alexnet = models.alexnet()\n",
        "alexnet.classifier[6] = nn.Linear(4096,num_classes)\n",
        "\n",
        "vgg16 = models.vgg16()\n",
        "vgg16.classifier[6] = nn.Linear(4096,num_classes)\n",
        "\n",
        "squeezenet = models.squeezenet1_0()\n",
        "squeezenet.classifier[1] = nn.Conv2d(512, num_classes, kernel_size=(1,1), stride=(1,1))\n",
        "\n",
        "inception = models.inception_v3(aux_logits=False)  #'N x 3 x 299 x 299'\n",
        "#inception.AuxLogits.fc = nn.Linear(768, num_classes)\n",
        "inception.fc = nn.Linear(2048, num_classes)\n",
        "\n",
        "mobilenet_v3_small = models.mobilenet_v3_small()\n",
        "mobilenet_v3_small.classifier[0] = nn.Linear(in_features=576, out_features=4096, bias=True)\n",
        "mobilenet_v3_small.classifier[3] = nn.Linear(4096,num_classes,bias=True)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rDX7cTZ5Od_w",
        "outputId": "a9f44625-efed-4647-e411-267c09d0e6ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/inception.py:83: FutureWarning: The default weight initialization of inception_v3 will be changed in future releases of torchvision. If you wish to keep the old behavior (which leads to long initialization times due to scipy/scipy#11299), please set init_weights=True.\n",
            "  ' due to scipy/scipy#11299), please set init_weights=True.', FutureWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_stack = [resnet18,resnet34,resnet50, alexnet, vgg16, squeezenet,inception, mobilenet_v3_small ]\n",
        "ModelNames = [str(imodel).split('(')[0] for imodel in model_stack]"
      ],
      "metadata": {
        "id": "IyOBYTBpUuOP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Пример батча"
      ],
      "metadata": {
        "id": "ijLkV0CLUfEn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "init = torch.Tensor(data_to_nn[0:4]).transpose(1,3)\n",
        "\n",
        "for imodel in [resnet18,resnet34,resnet50,alexnet, vgg16, squeezenet,mobilenet_v3_small ]:\n",
        "  ModelName = str(imodel).split('(')[0]\n",
        "  print(ModelName) \n",
        "  print(imodel(init).size(),'\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cmWUFIOAPFwR",
        "outputId": "328f09a9-06d7-43e8-b621-f342e7cb5a81"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ResNet\n",
            "torch.Size([4, 3]) \n",
            "\n",
            "ResNet\n",
            "torch.Size([4, 3]) \n",
            "\n",
            "ResNet\n",
            "torch.Size([4, 3]) \n",
            "\n",
            "AlexNet\n",
            "torch.Size([4, 3]) \n",
            "\n",
            "VGG\n",
            "torch.Size([4, 3]) \n",
            "\n",
            "SqueezeNet\n",
            "torch.Size([4, 3]) \n",
            "\n",
            "MobileNetV3\n",
            "torch.Size([4, 3]) \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from skimage.transform import resize\n",
        "len_N = 4\n",
        "init_incept = torch.Tensor(resize(data_to_nn[0:len_N],(len_N,299,299,3))).transpose(1,3)\n",
        "init_incept.size()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j_EjFtDBXzaO",
        "outputId": "24bfda2d-ed8c-4223-cbfa-3f84a1fec94e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4, 3, 299, 299])"
            ]
          },
          "metadata": {},
          "execution_count": 144
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output = inception(init_incept)\n",
        "torch.nn.functional.softmax(output, dim=0)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BTWD1g8FYGEC",
        "outputId": "96668c27-5605-446d-a51b-30d11dee1dab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.1990, 0.3022, 0.3035],\n",
              "        [0.3283, 0.3180, 0.2667],\n",
              "        [0.2399, 0.1649, 0.2031],\n",
              "        [0.2327, 0.2148, 0.2267]], grad_fn=<SoftmaxBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 143
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ZFCm67kmYgWu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "96-a-RwdbCLl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "rHBuXuHcbExU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Применение моделей"
      ],
      "metadata": {
        "id": "95s8UCGqdgti"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision.models as models\n",
        "import torch\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "\n",
        "NUM_CLASSES = 24\n",
        "\n",
        "def crtclass(mdTp,num_classes=24):\n",
        "  if mdTp == 'Res18':\n",
        "    modelF = models.resnet18()\n",
        "    modelF.fc = nn.Linear(512, num_classes)\n",
        "  elif mdTp == 'Res34':\n",
        "    modelF = models.resnet34()\n",
        "    modelF.fc = nn.Linear(512, num_classes)\n",
        "  elif mdTp == 'Res50':\n",
        "    modelF = models.resnet50()\n",
        "    modelF.fc = nn.Linear(2048, num_classes)\n",
        "  elif mdTp == 'Alex':\n",
        "    modelF = models.alexnet()\n",
        "    modelF.classifier[6] = nn.Linear(4096,num_classes)\n",
        "  elif mdTp == 'VGG':\n",
        "    modelF = models.vgg16()\n",
        "    modelF.classifier[6] = nn.Linear(4096,num_classes)\n",
        "  elif mdTp == 'Squeez':\n",
        "    modelF = models.squeezenet1_0()\n",
        "    modelF.classifier[1] = nn.Conv2d(512, num_classes, kernel_size=(1,1), stride=(1,1))\n",
        "  elif mdTp == 'Modile_v3':\n",
        "    modelF = models.mobilenet_v3_small()\n",
        "    modelF.classifier[0] = nn.Linear(in_features=576, out_features=4096, bias=True)\n",
        "    modelF.classifier[3] = nn.Linear(4096,num_classes,bias=True)\n",
        "  else:\n",
        "    assert False, 'no model'\n",
        "  return modelF"
      ],
      "metadata": {
        "id": "5p3btFOIdlx2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model  = crtclass('Res18')"
      ],
      "metadata": {
        "id": "qozovP2BeVdH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model(init)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f5oqyQWKei5K",
        "outputId": "54cb5969-f3a9-40b8-942f-84657bb07b64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.8238, -0.9891,  0.1152,  0.8391,  0.1100,  0.4369,  0.1683, -0.1972,\n",
              "         -0.1902, -0.1030,  1.3006, -0.3946,  0.4172,  0.2539,  0.1176,  0.4591,\n",
              "         -0.0025, -0.1073,  0.5338, -0.2554,  0.5985,  0.7607,  0.5611, -0.7475],\n",
              "        [-0.7351, -0.7711,  0.0317,  0.7263, -0.0838,  0.1344,  0.0955, -0.1218,\n",
              "         -0.0711, -0.0356,  0.7619, -0.0765,  0.3333,  0.1243,  0.1694,  0.2714,\n",
              "         -0.1433,  0.0771,  0.4070, -0.0550,  0.5891,  0.6991,  0.4625, -0.6502],\n",
              "        [-0.7955, -0.8138,  0.0370,  0.7901,  0.1141,  0.3974,  0.0375, -0.2160,\n",
              "         -0.1765, -0.0187,  1.0933, -0.2780,  0.5563,  0.1860,  0.0890,  0.4145,\n",
              "         -0.0428,  0.0248,  0.5268, -0.1165,  0.4657,  0.7178,  0.5951, -0.8045],\n",
              "        [-0.5852, -0.7955,  0.1387,  0.7437, -0.1796,  0.2990,  0.0609, -0.0935,\n",
              "         -0.1755,  0.0277,  0.7812, -0.1039,  0.3799,  0.0659,  0.1737,  0.2862,\n",
              "         -0.2631,  0.0210,  0.4816, -0.2182,  0.6061,  0.7948,  0.4368, -0.7184]],\n",
              "       grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 156
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "JPhjTOU7ev0n"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}