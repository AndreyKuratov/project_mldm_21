{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MLDM_TP_short_cuts.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMGQYgpLkfI/WCVFUii6lK5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AndreyKuratov/project_mldm_21/blob/main/MLDM_TP_short_cuts.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8lNBbUl1Hieq",
        "outputId": "53c73a72-34c5-4c41-85f1-dc3ec8e378f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F5iFVt49GN16"
      },
      "outputs": [],
      "source": [
        "from skimage.transform import resize\n",
        "from skimage.util import random_noise\n",
        "from skimage.filters import gaussian\n",
        "from skimage import exposure\n",
        "import cv2\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "def addNoisy(img):\n",
        "    noise_img = random_noise(img)\n",
        "    return addChannels(noise_img)\n",
        "\n",
        "def contrast_stretching(img):\n",
        "    p2, p98 = np.percentile(img, (2, 98))\n",
        "    contrast_img = exposure.rescale_intensity(img, in_range=(p2, p98))\n",
        "    return addChannels(contrast_img)\n",
        "\n",
        "def log_correction(img):\n",
        "    log_img = exposure.adjust_log(img)\n",
        "    return addChannels(log_img)\n",
        "\n",
        "def randomGaussian(img):\n",
        "    gaussian_img = gaussian(img, sigma=random.randint(0, 5))\n",
        "    return addChannels(gaussian_img)\n",
        "\n",
        "def addChannels(img):\n",
        "    return np.stack((img, img, img))\n",
        "\n",
        "def spec_to_image(spec):    \n",
        "    spec = resize(spec, (224, 400))\n",
        "    eps=1e-6\n",
        "    mean = spec.mean()\n",
        "    std = spec.std()\n",
        "    spec_norm = (spec - mean) / (std + eps)\n",
        "    spec_min, spec_max = spec_norm.min(), spec_norm.max()\n",
        "    spec_scaled = 255 * (spec_norm - spec_min) / (spec_max - spec_min)\n",
        "    spec_scaled = spec_scaled.astype(np.uint8)\n",
        "    spec_scaled = np.asarray(spec_scaled)\n",
        "    return spec_scaled"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import librosa\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class AudioData(Dataset):\n",
        "    def __init__(self, _data, data_type):\n",
        "        self.data = []\n",
        "        self.labels = []\n",
        "        for i in range(0, len(_data)):\n",
        "            # All sound files are 48000 bitrate, no need to slowly resample\n",
        "            wav, sr = librosa.load('/content/drive/MyDrive/MLDM_proj/train/' + _data[i][0] + '.flac', sr=None)\n",
        "\n",
        "            t_min = float(_data[i][3]) * sr\n",
        "            t_max = float(_data[i][5]) * sr\n",
        "\n",
        "            # Positioning sound slice\n",
        "            center = np.round((t_min + t_max) / 2)\n",
        "            beginning = center - length / 2\n",
        "            if beginning < 0:\n",
        "                beginning = 0\n",
        "\n",
        "            ending = beginning + length\n",
        "            if ending > len(wav):\n",
        "                ending = len(wav)\n",
        "                beginning = ending - length\n",
        "\n",
        "            slice = wav[int(beginning):int(ending)]\n",
        "            \n",
        "            spec=librosa.feature.melspectrogram(slice, sr=sr,n_fft=fft,hop_length=hop,fmin=fmin,fmax=fmax)\n",
        "            spec_db=librosa.power_to_db(spec,top_db=80)\n",
        "            \n",
        "            img = spec_to_image(spec_db)\n",
        "            mel_spec = np.stack((img, img, img))\n",
        "            self.data.append(mel_spec)\n",
        "            label = int(_data[i][1])\n",
        "            self.labels.append(label)\n",
        "            \n",
        "            if data_type == \"train\":\n",
        "                augmentation_functions = [\n",
        "                    addNoisy, contrast_stretching,\n",
        "                    randomGaussian, log_correction\n",
        "                ]\n",
        "                for fun in augmentation_functions:\n",
        "                    mel_spec = fun(img)\n",
        "                    self.data.append(mel_spec)\n",
        "                    self.labels.append(label)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.data[idx], self.labels[idx]"
      ],
      "metadata": {
        "id": "TBc-YdnbHRpn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import random\n",
        "\n",
        "fft = 2048\n",
        "hop = 512\n",
        "# Less rounding errors this way\n",
        "sr = 48000\n",
        "length = 10 * sr\n",
        "\n",
        "with open('/content/drive/MyDrive/MLDM_proj/train_tp.csv') as f:\n",
        "    reader = csv.reader(f)\n",
        "    next(reader, None)\n",
        "    data = list(reader)\n",
        "\n",
        "# Check minimum/maximum frequencies for bird calls\n",
        "# Not neccesary, but there are usually plenty of noise in low frequencies, and removing it helps\n",
        "fmin = 24000\n",
        "fmax = 0\n",
        "\n",
        "# Skip header row (recording_id,species_id,songtype_id,t_min,f_min,t_max,f_max) and start from 1 instead of 0\n",
        "for i in range(0, len(data)):\n",
        "    if fmin > float(data[i][4]):\n",
        "        fmin = float(data[i][4])\n",
        "    if fmax < float(data[i][6]):\n",
        "        fmax = float(data[i][6])\n",
        "# Get some safety margin\n",
        "fmin = int(fmin * 0.9)\n",
        "fmax = int(fmax * 1.1)\n",
        "print('Minimum frequency: ' + str(fmin) + ', maximum frequency: ' + str(fmax))\n",
        "\n",
        "percentage_train = 90\n",
        "random.shuffle(data)\n",
        "total = len(data)\n",
        "train_data_amount = round(total / 100 * percentage_train)\n",
        "# train_audio = data[:train_data_amount]\n",
        "# val_audio = data[train_data_amount:]\n",
        "# train_data = AudioData(train_audio, \"train\")\n",
        "# valid_data = AudioData(val_audio, \"valid\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dhWymjr-HeTx",
        "outputId": "7d7441b0-74ca-4aa0-ca8f-878fb85f76b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Minimum frequency: 84, maximum frequency: 15056\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle"
      ],
      "metadata": {
        "id": "4s7EQRJAJve9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "common_dir = '/content/drive/MyDrive/MLDM_proj/'"
      ],
      "metadata": {
        "id": "SkKi0VzkNg48"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(common_dir + 'train_data_for_DL.pkl', 'wb') as f:\n",
        "  pickle.dump(train_data, f)\n",
        "\n",
        "with open(common_dir + 'valid_data_for_DL.pkl', 'wb') as f:\n",
        "  pickle.dump(valid_data, f)"
      ],
      "metadata": {
        "id": "NzE_SEDNMqxF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(common_dir + 'train_data_for_DL.pkl', 'rb') as f:\n",
        "  train_data = pickle.load(f)\n",
        "\n",
        "with open(common_dir + 'valid_data_for_DL.pkl', 'rb') as f:\n",
        "  valid_data = pickle.load(f)"
      ],
      "metadata": {
        "id": "ChKnboc6ZX33"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(train_data, batch_size=16, shuffle=True)\n",
        "valid_loader = DataLoader(valid_data, batch_size=16, shuffle=True)"
      ],
      "metadata": {
        "id": "rghZbKkkZVlg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"train\", len(train_data))\n",
        "print(\"valid\", len(valid_data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4oIc85daIGcv",
        "outputId": "cc16d48d-dd0f-42da-8d17-0db5cc0e7954"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train 5470\n",
            "valid 122\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.models import resnet50\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.optim import lr_scheduler\n",
        "import copy"
      ],
      "metadata": {
        "id": "_E9K32hnIbcw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_birds = 24\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    device=torch.device('cuda:0')\n",
        "else:\n",
        "    device=torch.device('cpu')\n",
        "\n",
        "resnet_model = resnet50(pretrained=True)\n",
        "num_ftrs = resnet_model.fc.in_features\n",
        "resnet_model.fc = nn.Linear(num_ftrs, num_birds)\n",
        "resnet_model = resnet_model.to(device)"
      ],
      "metadata": {
        "id": "69nnDmXKIbVl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "learning_rate = 2e-4\n",
        "optimizer = torch.optim.Adam(resnet_model.parameters(), lr=learning_rate)\n",
        "epochs = 20\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "def setlr(optimizer, lr):\n",
        "    for param_group in optimizer.param_groups:\n",
        "        param_group['lr'] = lr\n",
        "    return optimizer\n",
        "\n",
        "def lr_decay(optimizer, epoch):\n",
        "    if epoch%10==0:\n",
        "        new_lr = learning_rate / (10**(epoch//10))\n",
        "        optimizer = setlr(optimizer, new_lr)\n",
        "        print(f'Changed learning rate to {new_lr}')\n",
        "    return optimizer\n",
        "\n",
        "def train(model, loss_fn, train_loader, valid_loader, epochs, optimizer, change_lr=None):\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "    train_losses = []\n",
        "    valid_losses = []\n",
        "    \n",
        "    for epoch in tqdm(range(1,epochs+1)):\n",
        "        model.train()\n",
        "        batch_losses=[]\n",
        "        if change_lr:\n",
        "            optimizer = change_lr(optimizer, epoch)\n",
        "        for i, data in enumerate(train_loader):\n",
        "            x, y = data\n",
        "            optimizer.zero_grad()\n",
        "            x = x.to(device, dtype=torch.float32)\n",
        "            y = y.to(device, dtype=torch.long)\n",
        "            y_hat = model(x)\n",
        "            loss = loss_fn(y_hat, y)\n",
        "            loss.backward()\n",
        "            batch_losses.append(loss.item())\n",
        "            optimizer.step()\n",
        "            \n",
        "        train_losses.append(batch_losses)\n",
        "        print(f'Epoch - {epoch} Train-Loss : {np.mean(train_losses[-1])}')\n",
        "        model.eval()\n",
        "        batch_losses=[]\n",
        "        trace_y = []\n",
        "        trace_yhat = []\n",
        "        \n",
        "        for i, data in enumerate(valid_loader):\n",
        "            x, y = data\n",
        "            x = x.to(device, dtype=torch.float32)\n",
        "            y = y.to(device, dtype=torch.long)\n",
        "            y_hat = model(x)\n",
        "            loss = loss_fn(y_hat, y)\n",
        "            trace_y.append(y.cpu().detach().numpy())\n",
        "            trace_yhat.append(y_hat.cpu().detach().numpy())      \n",
        "            batch_losses.append(loss.item())\n",
        "        valid_losses.append(batch_losses)\n",
        "        trace_y = np.concatenate(trace_y)\n",
        "        trace_yhat = np.concatenate(trace_yhat)\n",
        "        accuracy = np.mean(trace_yhat.argmax(axis=1)==trace_y)\n",
        "        print(f'Epoch - {epoch} Valid-Loss : {np.mean(valid_losses[-1])} Valid-Accuracy : {accuracy}')\n",
        "        # deep copy the model\n",
        "        if accuracy > best_acc:\n",
        "            best_acc = accuracy\n",
        "            best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model"
      ],
      "metadata": {
        "id": "rhM1B7RsIbMW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resnet_model = train(resnet_model, loss_fn, train_loader, valid_loader, epochs, optimizer, lr_decay)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NRPCvvgSIpLr",
        "outputId": "ae59d50e-afc7-4313-f61c-6f135f1829ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/20 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch - 1 Train-Loss : 2.136324789788988\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  5%|▌         | 1/20 [01:05<20:40, 65.28s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch - 1 Valid-Loss : 1.087562769651413 Valid-Accuracy : 0.6967213114754098\n",
            "Epoch - 2 Train-Loss : 1.2858019316057017\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|█         | 2/20 [02:09<19:21, 64.54s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch - 2 Valid-Loss : 1.0000904835760593 Valid-Accuracy : 0.7704918032786885\n",
            "Epoch - 3 Train-Loss : 0.7556469241778055\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 15%|█▌        | 3/20 [03:13<18:13, 64.31s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch - 3 Valid-Loss : 0.7308412455022335 Valid-Accuracy : 0.7786885245901639\n",
            "Epoch - 4 Train-Loss : 0.4789674313009134\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 4/20 [04:17<17:06, 64.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch - 4 Valid-Loss : 0.8124755509197712 Valid-Accuracy : 0.8114754098360656\n",
            "Epoch - 5 Train-Loss : 0.29495610265682143\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 25%|██▌       | 5/20 [05:21<16:01, 64.11s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch - 5 Valid-Loss : 0.6613836102187634 Valid-Accuracy : 0.819672131147541\n",
            "Epoch - 6 Train-Loss : 0.18250837183301474\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|███       | 6/20 [06:25<14:56, 64.07s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch - 6 Valid-Loss : 0.585271842777729 Valid-Accuracy : 0.8852459016393442\n",
            "Epoch - 7 Train-Loss : 0.14337755670792787\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 35%|███▌      | 7/20 [07:29<13:52, 64.06s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch - 7 Valid-Loss : 0.6586902406997979 Valid-Accuracy : 0.8524590163934426\n",
            "Epoch - 8 Train-Loss : 0.14124047669598408\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 8/20 [08:33<12:48, 64.03s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch - 8 Valid-Loss : 0.5371331474743783 Valid-Accuracy : 0.8852459016393442\n",
            "Epoch - 9 Train-Loss : 0.09151945298412346\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 45%|████▌     | 9/20 [09:37<11:43, 63.98s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch - 9 Valid-Loss : 0.6235972139984369 Valid-Accuracy : 0.8442622950819673\n",
            "Changed learning rate to 2e-05\n",
            "Epoch - 10 Train-Loss : 0.036384831412766154\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|█████     | 10/20 [10:41<10:39, 63.98s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch - 10 Valid-Loss : 0.5331049095839262 Valid-Accuracy : 0.8770491803278688\n",
            "Epoch - 11 Train-Loss : 0.011244049768933034\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 55%|█████▌    | 11/20 [11:45<09:35, 63.95s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch - 11 Valid-Loss : 0.5521361278370023 Valid-Accuracy : 0.8770491803278688\n",
            "Epoch - 12 Train-Loss : 0.009660310752224177\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|██████    | 12/20 [12:48<08:31, 63.95s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch - 12 Valid-Loss : 0.5766796600073576 Valid-Accuracy : 0.8852459016393442\n",
            "Epoch - 13 Train-Loss : 0.006813151791248585\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 65%|██████▌   | 13/20 [13:52<07:27, 63.93s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch - 13 Valid-Loss : 0.5255470285192132 Valid-Accuracy : 0.8770491803278688\n",
            "Epoch - 14 Train-Loss : 0.006946088260445439\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 70%|███████   | 14/20 [14:56<06:23, 63.94s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch - 14 Valid-Loss : 0.5555051788687706 Valid-Accuracy : 0.860655737704918\n",
            "Epoch - 15 Train-Loss : 0.0049047641170535195\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 75%|███████▌  | 15/20 [16:01<05:20, 64.07s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch - 15 Valid-Loss : 0.5522448448464274 Valid-Accuracy : 0.8852459016393442\n",
            "Epoch - 16 Train-Loss : 0.00422320132925344\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|████████  | 16/20 [17:05<04:16, 64.18s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch - 16 Valid-Loss : 0.5201553450897336 Valid-Accuracy : 0.8934426229508197\n",
            "Epoch - 17 Train-Loss : 0.004250912655965965\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 85%|████████▌ | 17/20 [18:10<03:13, 64.43s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch - 17 Valid-Loss : 0.5591669762507081 Valid-Accuracy : 0.8770491803278688\n",
            "Epoch - 18 Train-Loss : 0.004222019907507136\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%|█████████ | 18/20 [19:14<02:08, 64.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch - 18 Valid-Loss : 0.5251013187225908 Valid-Accuracy : 0.8770491803278688\n",
            "Epoch - 19 Train-Loss : 0.004588028710437272\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 95%|█████████▌| 19/20 [20:19<01:04, 64.32s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch - 19 Valid-Loss : 0.5755440257489681 Valid-Accuracy : 0.8770491803278688\n",
            "Changed learning rate to 2e-06\n",
            "Epoch - 20 Train-Loss : 0.006344433967032598\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [21:23<00:00, 64.17s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch - 20 Valid-Loss : 0.5500521569047123 Valid-Accuracy : 0.8852459016393442\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(resnet_model.state_dict(), common_dir + 'model_short_slices')"
      ],
      "metadata": {
        "id": "PjDAq5mmdyfq"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_test_file(f):\n",
        "    wav, sr = librosa.load('/content/drive/MyDrive/MLDM_proj/test/' + f, sr=None)\n",
        "\n",
        "    # Split for enough segments to not miss anything\n",
        "    segments = len(wav) / length\n",
        "    segments = int(np.ceil(segments))\n",
        "    \n",
        "    mel_array = []\n",
        "    \n",
        "    for i in range(0, segments):\n",
        "        # Last segment going from the end\n",
        "        if (i + 1) * length > len(wav):\n",
        "            slice = wav[len(wav) - length:len(wav)]\n",
        "        else:\n",
        "            slice = wav[i * length:(i + 1) * length]\n",
        "        \n",
        "        # Same mel spectrogram as before\n",
        "        spec=librosa.feature.melspectrogram(slice, sr=sr,n_fft=fft,hop_length=hop,fmin=fmin,fmax=fmax)\n",
        "        spec_db=librosa.power_to_db(spec,top_db=80)\n",
        "\n",
        "        img = spec_to_image(spec_db)\n",
        "        mel_spec = np.stack((img, img, img))\n",
        "        mel_array.append(mel_spec)\n",
        "    \n",
        "    return mel_array"
      ],
      "metadata": {
        "id": "osSXQoLrIpCO"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "    \n",
        "# Prediction loop\n",
        "print('Starting prediction loop')\n",
        "with open(common_dir + 'submission.csv', 'w', newline='') as csvfile:\n",
        "    submission_writer = csv.writer(csvfile, delimiter=',')\n",
        "    submission_writer.writerow(['recording_id','s0','s1','s2','s3','s4','s5','s6','s7','s8','s9','s10','s11',\n",
        "                               's12','s13','s14','s15','s16','s17','s18','s19','s20','s21','s22','s23'])\n",
        "    \n",
        "    test_files = os.listdir(common_dir + 'test/')\n",
        "    print(len(test_files))\n",
        "    \n",
        "    # Every test file is split on several chunks and prediction is made for each chunk\n",
        "    for i in range(0, len(test_files)):\n",
        "        data = load_test_file(test_files[i])\n",
        "        data = torch.tensor(data)\n",
        "        data = data.float()\n",
        "        if torch.cuda.is_available():\n",
        "            data = data.cuda()\n",
        "\n",
        "        output = resnet_model(data)\n",
        "\n",
        "        # Taking max prediction from all slices per bird species\n",
        "        # Usually you want Sigmoid layer here to convert output to probabilities\n",
        "        # In this competition only relative ranking matters, and not the exact value of prediction, so we can use it directly\n",
        "        maxed_output = torch.max(output, dim=0)[0]\n",
        "        maxed_output = maxed_output.cpu().detach()\n",
        "        \n",
        "        file_id = str.split(test_files[i], '.')[0]\n",
        "        write_array = [file_id]\n",
        "        \n",
        "        for out in maxed_output:\n",
        "            write_array.append(out.item())\n",
        "\n",
        "        submission_writer.writerow(write_array)\n",
        "        if i % 100 == 0 and i > 0:\n",
        "            print('Predicted for ' + str(i) + ' of ' + str(len(test_files) + 1) + ' files')\n",
        "\n",
        "print('Submission generated')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yl4VTSNrIoqL",
        "outputId": "27e54b54-54d3-45ce-a078-cd12e84c30ff"
      },
      "execution_count": 18,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting prediction loop\n",
            "1992\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted for 100 of 1993 files\n",
            "Predicted for 200 of 1993 files\n",
            "Predicted for 300 of 1993 files\n",
            "Predicted for 400 of 1993 files\n",
            "Predicted for 500 of 1993 files\n",
            "Predicted for 600 of 1993 files\n",
            "Predicted for 700 of 1993 files\n",
            "Predicted for 800 of 1993 files\n",
            "Predicted for 900 of 1993 files\n",
            "Predicted for 1000 of 1993 files\n",
            "Predicted for 1100 of 1993 files\n",
            "Predicted for 1200 of 1993 files\n",
            "Predicted for 1300 of 1993 files\n",
            "Predicted for 1400 of 1993 files\n",
            "Predicted for 1500 of 1993 files\n",
            "Predicted for 1600 of 1993 files\n",
            "Predicted for 1700 of 1993 files\n",
            "Predicted for 1800 of 1993 files\n",
            "Predicted for 1900 of 1993 files\n",
            "Submission generated\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "_ijQbvFVTrLs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}